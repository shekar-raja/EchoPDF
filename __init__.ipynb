{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EchoPDF\n",
    "\n",
    "EchoPDF is a Retrieval-Augmented Generation (RAG) tool that enables users to upload any PDF document, ask questions about its content, and receive tailored, contextually accurate answers. Designed to enhance document accessibility, EchoPDF combines NLP and deep learning to extract and retrieve specific information, providing quick and insightful responses directly from uploaded PDFs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# from utils.helper_functions import open_and_read_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: File already exists.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Path to pdf\n",
    "pdf_path = \"human_nutrition.pdf\"\n",
    "\n",
    "# Import the pdf\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"[INFO]: File doesn't exist\")\n",
    "    file_name = pdf_path\n",
    "\n",
    "    url = os.getenv(\"pdf_url\")\n",
    "    \n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Open the file and save it\n",
    "        with open(file_name, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"[INFO]: File has been downloaded and saved as {file_name}\")\n",
    "    else:\n",
    "        print(f\"[INFO]: Failed to download the file. Status code: {response.status_code}\")\n",
    "else:\n",
    "    print(f\"[INFO]: File already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/echopdf/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def format_text(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs text formatting and returns formatted text\n",
    "    \"\"\"\n",
    "    cleaned_text = input.replace(\"\\n\", \" \").strip()\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def open_and_read_pdf(pdf_path: str):\n",
    "    \"\"\"\n",
    "    Opens the pdf, creates a list of dictionaries for each page, and returns the list\n",
    "    \"\"\"\n",
    "    document = fitz.open(pdf_path)\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(document)):\n",
    "        text = page.get_text()\n",
    "        text = format_text(input=text)\n",
    "        pages_and_texts.append({\n",
    "                \"page_number\": page_number - 41,\n",
    "                \"page_char_count\": len(text),\n",
    "                \"page_word_count\": len(text.split(\" \")),\n",
    "                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                \"page_token_count\": len(text) / 4,\n",
    "                \"text\": text  \n",
    "        })\n",
    "        \n",
    "    return pages_and_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1208it [00:01, 640.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': -41,\n",
       "  'page_char_count': 29,\n",
       "  'page_word_count': 4,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 7.25,\n",
       "  'text': 'Human Nutrition: 2020 Edition'},\n",
       " {'page_number': -40,\n",
       "  'page_char_count': 0,\n",
       "  'page_word_count': 1,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 0.0,\n",
       "  'text': ''},\n",
       " {'page_number': -39,\n",
       "  'page_char_count': 320,\n",
       "  'page_word_count': 54,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 80.0,\n",
       "  'text': 'Human Nutrition: 2020  Edition  UNIVERSITY OF HAWAI‘I AT MĀNOA  FOOD SCIENCE AND HUMAN  NUTRITION PROGRAM  ALAN TITCHENAL, SKYLAR HARA,  NOEMI ARCEO CAACBAY, WILLIAM  MEINKE-LAU, YA-YUN YANG, MARIE  KAINOA FIALKOWSKI REVILLA,  JENNIFER DRAPER, GEMADY  LANGFELDER, CHERYL GIBBY, CHYNA  NICOLE CHUN, AND ALLISON  CALABRESE'},\n",
       " {'page_number': -38,\n",
       "  'page_char_count': 212,\n",
       "  'page_word_count': 32,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 53.0,\n",
       "  'text': 'Human Nutrition: 2020 Edition by University of Hawai‘i at Mānoa Food Science and  Human Nutrition Program is licensed under a Creative Commons Attribution 4.0  International License, except where otherwise noted.'},\n",
       " {'page_number': -37,\n",
       "  'page_char_count': 797,\n",
       "  'page_word_count': 145,\n",
       "  'page_sentence_count_raw': 2,\n",
       "  'page_token_count': 199.25,\n",
       "  'text': 'Contents  Preface  University of Hawai‘i at Mānoa Food Science and  Human Nutrition Program and Human Nutrition  Program  xxv  About the Contributors  University of Hawai‘i at Mānoa Food Science and  Human Nutrition Program and Human Nutrition  Program  xxvi  Acknowledgements  University of Hawai‘i at Mānoa Food Science and  Human Nutrition Program and Human Nutrition  Program  xl  Part\\xa0I.\\xa0Chapter 1. Basic Concepts in Nutrition  Introduction  University of Hawai‘i at Mānoa Food Science and  Human Nutrition Program and Human Nutrition  Program  3  Food Quality  University of Hawai‘i at Mānoa Food Science and  Human Nutrition Program and Human Nutrition  Program  14  Units of Measure  University of Hawai‘i at Mānoa Food Science and  Human Nutrition Program and Human Nutrition  Program  18'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's open the pdf and read it's content\n",
    "pages_and_text = open_and_read_pdf(pdf_path=\"human_nutrition.pdf\")\n",
    "pages_and_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 341,\n",
       "  'page_char_count': 1946,\n",
       "  'page_word_count': 336,\n",
       "  'page_sentence_count_raw': 17,\n",
       "  'page_token_count': 486.5,\n",
       "  'text': 'initially contain polyunsaturated fatty acids. When the process of  hydrogenation is not complete, for example, not all carbon double  bonds have been saturated the end result is a partially hydrogenated  oil. The resulting oil is not fully solid. Total hydrogenation makes  the oil very hard and virtually unusable. Some newer products are  now using fully hydrogenated oil combined with nonhydrogenated  vegetable oils to create a usable fat.  Manufacturers favor hydrogenation as a way to prevent oxidation  of oils and ensure longer shelf life. Partially hydrogenated vegetable  oils are used in the fast food and processed food industries because  they impart the desired texture and crispness to baked and fried  foods. Partially hydrogenated vegetable oils are more resistant to  breakdown from extremely hot cooking temperatures. Because  hydrogenated oils have a high smoking point they are very well  suited for frying. In addition, processed vegetable oils are cheaper  than fats obtained from animal sources, making them a popular  choice for the food industry.  Trans fatty acids occur in small amounts in nature, mostly in  dairy products. However, the trans fats that are used by the food  industry are produced from the hydrogenation process. Trans fats  are a result of the partial hydrogenation of unsaturated fatty acids,  which cause them to have a trans configuration, rather than the  naturally occurring cis configuration.  Health Implications of Trans Fats  No trans fats! Zero trans fats! We see these advertisements on a  regular basis. So widespread is the concern over the issue that  restaurants, food manufacturers, and even fast-food establishments  proudly tout either the absence or the reduction of these fats within  their products. Amid the growing awareness that trans fats may not  be good for you, let’s get right to the heart of the matter. Why are  trans fats so bad?  Lipids and the Food Industry  |  341'},\n",
       " {'page_number': 1010,\n",
       "  'page_char_count': 749,\n",
       "  'page_word_count': 123,\n",
       "  'page_sentence_count_raw': 5,\n",
       "  'page_token_count': 187.25,\n",
       "  'text': 'available in the web-based textbook and not available in the  downloadable versions (EPUB, Digital PDF, Print_PDF, or  Open Document).  Learning activities may be used across various mobile  devices, however, for the best user experience it is strongly  recommended that users complete these activities using a  desktop or laptop computer and in Google Chrome.  \\xa0 An interactive or media element has been  excluded from this version of the text. You can  view it online here:  http://pressbooks.oer.hawaii.edu/ humannutrition2/?p=527  \\xa0 An interactive or media element has been  excluded from this version of the text. You can  view it online here:  http://pressbooks.oer.hawaii.edu/ humannutrition2/?p=527  1010  |  The Causes of Food Contamination'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(pages_and_text, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-41</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>Human Nutrition: 2020 Edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-39</td>\n",
       "      <td>320</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>80.00</td>\n",
       "      <td>Human Nutrition: 2020  Edition  UNIVERSITY OF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-38</td>\n",
       "      <td>212</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>53.00</td>\n",
       "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-37</td>\n",
       "      <td>797</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>199.25</td>\n",
       "      <td>Contents  Preface  University of Hawai‘i at Mā...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0          -41               29                4                        1   \n",
       "1          -40                0                1                        1   \n",
       "2          -39              320               54                        1   \n",
       "3          -38              212               32                        1   \n",
       "4          -37              797              145                        2   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0              7.25                      Human Nutrition: 2020 Edition  \n",
       "1              0.00                                                     \n",
       "2             80.00  Human Nutrition: 2020  Edition  UNIVERSITY OF ...  \n",
       "3             53.00  Human Nutrition: 2020 Edition by University of...  \n",
       "4            199.25  Contents  Preface  University of Hawai‘i at Mā...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>198.30</td>\n",
       "      <td>9.97</td>\n",
       "      <td>287.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.76</td>\n",
       "      <td>6.19</td>\n",
       "      <td>140.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>190.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>214.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>271.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>400.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>429.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>577.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           198.30                     9.97   \n",
       "std         348.86           560.38            95.76                     6.19   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     4.00   \n",
       "50%         562.50          1231.50           214.50                    10.00   \n",
       "75%         864.25          1603.50           271.00                    14.00   \n",
       "max        1166.00          2308.00           429.00                    32.00   \n",
       "\n",
       "       page_token_count  \n",
       "count           1208.00  \n",
       "mean             287.00  \n",
       "std              140.10  \n",
       "min                0.00  \n",
       "25%              190.50  \n",
       "50%              307.88  \n",
       "75%              400.88  \n",
       "max              577.00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further text processing (splitting pages into sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [00:01<00:00, 941.46it/s] \n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "for item in tqdm(pages_and_text):\n",
    "    # if (item[\"text\"]):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "\n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 407,\n",
       "  'page_char_count': 1096,\n",
       "  'page_word_count': 206,\n",
       "  'page_sentence_count_raw': 11,\n",
       "  'page_token_count': 274.0,\n",
       "  'text': '•  Get your protein from foods such as soybeans, tofu,  tempeh, lentils, and beans, beans, and more beans.  Many of these foods are high in zinc too.  •  Eat foods fortified with vitamins B12 and D and  calcium. Some examples are soy milk and fortified  cereals.  •  Get enough iron in your diet by eating kidney  beans, lentils, whole-grain cereals, and leafy green  vegetables.  •  To increase iron absorption, eat foods with vitamin  C at the same time.  •  Don’t forget that carbohydrates and fats are  required in your diet too, especially if you are  training. Eat whole-grain breads, cereals, and pastas.  For fats, eat an avocado, add some olive oil to a salad  or stir-fry, or spread some peanut or cashew butter  on a bran muffin.  Learning Activities  Technology Note: The second edition of the Human  Nutrition Open Educational Resource (OER) textbook  features interactive learning activities.\\xa0 These activities are  available in the web-based textbook and not available in the  downloadable versions (EPUB, Digital PDF, Print_PDF, or  Open Document).  Proteins in a Nutshell  |  407',\n",
       "  'sentences': ['•  Get your protein from foods such as soybeans, tofu,  tempeh, lentils, and beans, beans, and more beans.',\n",
       "   ' Many of these foods are high in zinc too.',\n",
       "   ' •  Eat foods fortified with vitamins B12 and D and  calcium.',\n",
       "   'Some examples are soy milk and fortified  cereals.',\n",
       "   ' •  Get enough iron in your diet by eating kidney  beans, lentils, whole-grain cereals, and leafy green  vegetables.',\n",
       "   ' •  To increase iron absorption, eat foods with vitamin  C at the same time.',\n",
       "   ' •  Don’t forget that carbohydrates and fats are  required in your diet too, especially if you are  training.',\n",
       "   'Eat whole-grain breads, cereals, and pastas.',\n",
       "   ' For fats, eat an avocado, add some olive oil to a salad  or stir-fry, or spread some peanut or cashew butter  on a bran muffin.',\n",
       "   ' Learning Activities  Technology Note: The second edition of the Human  Nutrition Open Educational Resource (OER) textbook  features interactive learning activities.',\n",
       "   '\\xa0 These activities are  available in the web-based textbook and not available in the  downloadable versions (EPUB, Digital PDF, Print_PDF, or  Open Document).',\n",
       "   ' Proteins in a Nutshell  |  407'],\n",
       "  'page_sentence_count_spacy': 12}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_text, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>198.30</td>\n",
       "      <td>9.97</td>\n",
       "      <td>287.00</td>\n",
       "      <td>10.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.76</td>\n",
       "      <td>6.19</td>\n",
       "      <td>140.10</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>190.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>214.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>271.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>400.88</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>429.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           198.30                     9.97   \n",
       "std         348.86           560.38            95.76                     6.19   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     4.00   \n",
       "50%         562.50          1231.50           214.50                    10.00   \n",
       "75%         864.25          1603.50           271.00                    14.00   \n",
       "max        1166.00          2308.00           429.00                    32.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count           1208.00                    1208.00  \n",
       "mean             287.00                      10.32  \n",
       "std              140.10                       6.30  \n",
       "min                0.00                       0.00  \n",
       "25%              190.50                       5.00  \n",
       "50%              307.88                      10.00  \n",
       "75%              400.88                      15.00  \n",
       "max              577.00                      28.00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_text)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the sentences into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 10\n",
    "\n",
    "def split_sentences(input_list, slize_size = chunk_size):\n",
    "    return [input_list[i:i+slize_size] for i in range(0, len(input_list), slize_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [00:00<00:00, 940196.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the pages and text and split sentences into chunks\n",
    "for item in tqdm(pages_and_text):\n",
    "    item[\"sentence_chunks\"] = split_sentences(input_list=item[\"sentences\"])\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>198.30</td>\n",
       "      <td>9.97</td>\n",
       "      <td>287.00</td>\n",
       "      <td>10.32</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.76</td>\n",
       "      <td>6.19</td>\n",
       "      <td>140.10</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>190.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>214.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>271.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>400.88</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>429.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           198.30                     9.97   \n",
       "std         348.86           560.38            95.76                     6.19   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     4.00   \n",
       "50%         562.50          1231.50           214.50                    10.00   \n",
       "75%         864.25          1603.50           271.00                    14.00   \n",
       "max        1166.00          2308.00           429.00                    32.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count           1208.00                    1208.00     1208.00  \n",
       "mean             287.00                      10.32        1.53  \n",
       "std              140.10                       6.30        0.64  \n",
       "min                0.00                       0.00        0.00  \n",
       "25%              190.50                       5.00        1.00  \n",
       "50%              307.88                      10.00        1.00  \n",
       "75%              400.88                      15.00        2.00  \n",
       "max              577.00                      28.00        3.00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_text)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting each chunk into its own item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [00:00<00:00, 18520.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1843"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pages_and_chunks = []\n",
    "\n",
    "for item in tqdm(pages_and_text):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r\"\\.([A-Z])\", r\". \\1\", joined_sentence_chunk)\n",
    "\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4\n",
    "\n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>583.38</td>\n",
       "      <td>734.44</td>\n",
       "      <td>112.33</td>\n",
       "      <td>183.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>347.79</td>\n",
       "      <td>447.54</td>\n",
       "      <td>71.22</td>\n",
       "      <td>111.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>280.50</td>\n",
       "      <td>315.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>78.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>586.00</td>\n",
       "      <td>746.00</td>\n",
       "      <td>114.00</td>\n",
       "      <td>186.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>890.00</td>\n",
       "      <td>1118.50</td>\n",
       "      <td>173.00</td>\n",
       "      <td>279.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>1831.00</td>\n",
       "      <td>297.00</td>\n",
       "      <td>457.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count      1843.00           1843.00           1843.00            1843.00\n",
       "mean        583.38            734.44            112.33             183.61\n",
       "std         347.79            447.54             71.22             111.89\n",
       "min         -41.00             12.00              3.00               3.00\n",
       "25%         280.50            315.00             44.00              78.75\n",
       "50%         586.00            746.00            114.00             186.50\n",
       "75%         890.00           1118.50            173.00             279.62\n",
       "max        1166.00           1831.00            297.00             457.75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 176.5 | Text: • Binge-Eating Disorder. People who suffer from binge-eating disorder experience regular episodes of eating an extremely large amount of food in a short period of time. Binge eating is a compulsive behavior, and people who suffer from it typically feel it is beyond their control. This behavior often causes feelings of shame and embarrassment, and leads to obesity, high blood pressure, high cholesterol levels, Type 2 diabetes, and other health problems. Both males and females suffer from binge-eating disorder. It affects 1 to 5 percent of the 3. Eating Disorder Statistics. North Dakota State University.http://www.ndsu.edu/fileadmin/ counseling/Eating_Disorder_Statistics.pdf. Accessed March 5, 2012.\n",
      "Chunk token count: 187.0 | Text: usage. Learning Activities Technology Note: The second edition of the Human Nutrition Open Educational Resource (OER) textbook features interactive learning activities.  These activities are available in the web-based textbook and not available in the downloadable versions (EPUB, Digital PDF, Print_PDF, or Open Document). Learning activities may be used across various mobile devices, however, for the best user experience it is strongly recommended that users complete these activities using a desktop or laptop computer and in Google Chrome.   An interactive or media element has been excluded from this version of the text. You can view it online here: http://pressbooks.oer.hawaii.edu/ humannutrition2/?p=65   52 | Types of Scientific Studies\n",
      "Chunk token count: 47.5 | Text: Image by Jennifer Draper / CC BY 4.0 Image by CDC / Unsplash License Intuitive Eating Intuitive eating is a non-diet approach to eating that promotes a Calories In Versus Calories Out | 1073\n",
      "Chunk token count: 180.5 | Text: Sweeteners with Trade Name Calories Source/Origin Consumer Recommendations Controversial Issues Aspartame • NutraSweet • Equal 4 kcal/g Composed of two amino acids (phenylalanine + aspartic acid) + methanol. Two hundred times sweeter than sucrose. FDA set maximum Acceptable Daily Intakes (ADI):50 mg/kg body weight = 16 12 oz. diet soft drinks for adults. *Cannot be used in products requiring cooking. People with PKU should not consume aspartame. Children have potential to reach ADI if consuming many beverages, desserts, frozen desserts, and gums containing aspartame routinely. Saccharin • Sweet ‘n’ Low 0 kcal/g Discovered in 1878. The basic substance is benzoic sulfinide. Three hundred times sweeter than sucrose.\n",
      "Chunk token count: 390.75 | Text: inhibits milk secretion. Shortly after birth, the expulsion of the placenta triggers progesterone levels to fall, which activates lactation.15 When the infant suckles at the breast, levels of the hormone oxytocin rise to promote the release of breast milk from the breast when the infant suckles, which is known as the milk- ejection reflex. New mothers usually find that their appetite and thirst is greater than before pregnancy; it is recommended that they still focus on nutrient-dense foods to nourish their body and replace their body’s nutrient stores. A conservative rate of weight loss (1-2 pounds per week) during lactation does not usually impact the quantity or quality of breast milk, but maternal deficiencies in some nutrients have been described during lactation. The nutrient content of breastmilk does not change much based upon maternal diet for most nutrients. The RDA for energy is 330 additional Calories during the first six months of lactation and 400 additional Calories during the second six months of lactation. The energy needed to support breastfeeding comes from both increased intake and from stored fat. For example, during the first six months after her baby is born, the daily caloric cost for a lactating mother is 500 Calories, with 330 calories derived from increased intake and 170 Calories derived from maternal fat stores. This helps explain why breastfeeding may promote weight loss in new mothers. Lactating women should also drink 3.1 liters of liquids per day (about 13 cups) to avoid dehydration, according to the IOM.\n"
     ]
    }
   ],
   "source": [
    "min_token_length = 30\n",
    "\n",
    "for row in df[df[\"chunk_token_count\"] > min_token_length].sample(5).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': -39,\n",
       "  'sentence_chunk': 'Human Nutrition: 2020 Edition UNIVERSITY OF HAWAI‘I AT MĀNOA FOOD SCIENCE AND HUMAN NUTRITION PROGRAM ALAN TITCHENAL, SKYLAR HARA, NOEMI ARCEO CAACBAY, WILLIAM MEINKE-LAU, YA-YUN YANG, MARIE KAINOA FIALKOWSKI REVILLA, JENNIFER DRAPER, GEMADY LANGFELDER, CHERYL GIBBY, CHYNA NICOLE CHUN, AND ALLISON CALABRESE',\n",
       "  'chunk_char_count': 308,\n",
       "  'chunk_word_count': 42,\n",
       "  'chunk_token_count': 77.0},\n",
       " {'page_number': -38,\n",
       "  'sentence_chunk': 'Human Nutrition: 2020 Edition by University of Hawai‘i at Mānoa Food Science and Human Nutrition Program is licensed under a Creative Commons Attribution 4.0 International License, except where otherwise noted.',\n",
       "  'chunk_char_count': 210,\n",
       "  'chunk_word_count': 30,\n",
       "  'chunk_token_count': 52.5}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks_over_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echopdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
